{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9897,
     "status": "ok",
     "timestamp": 1656064396618,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "NTjjfCOXViPL",
    "outputId": "d2364786-7356-44ed-d029-6c6114ae6c6b"
   },
   "outputs": [],
   "source": [
    "#!git clone \"https://github.com/SriRamGovardhanam/wastedata-Mask_RCNN-multiple-classes.git\"\n",
    "\n",
    "# !pip install -r requirements.txt\n",
    "#%cd ./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN\n",
    "#!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16.2\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50FuwQB54fQ5"
   },
   "source": [
    "<b>usefull links </b>\n",
    "https://towardsdatascience.com/computer-vision-instance-segmentation-with-mask-r-cnn-7983502fcad1\n",
    "https://towardsdatascience.com/mask-rcnn-implementation-on-a-custom-dataset-fd9a878123d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMvi4k7kkpzn"
   },
   "source": [
    "<b> Please restart </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2ToWCNDydwk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1656065511522,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "7XQAUjTUyd__",
    "outputId": "334c4b8f-a8b9-43bf-aa73-badd5b7ab71f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'datasets-20220628T102320Z-004.zip',\n",
       " 'all class_orig_data.ipynb',\n",
       " 'wastedata-Mask_RCNN-multiple-classes',\n",
       " 'datasets-20220628T102320Z-002.zip',\n",
       " 'datasets',\n",
       " 'datasets-20220628T102320Z-001.zip',\n",
       " 'datasets-20220628T102320Z-003.zip']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%cd /content/drive/MyDrive/PAVE DOUGH DEVELOPMENT (USMAN)/Instance Segmentation Pave\n",
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:05:42.910036: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-06-28 16:05:42.934620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2022-06-28 16:05:42.936739: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb9b9e6a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-28 16:05:42.936755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-06-28 16:05:42.938880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-28 16:05:43.318499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb9b9d28e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-06-28 16:05:43.318549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2022-06-28 16:05:43.319107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 major: 8 minor: 6 memoryClockRate(GHz): 1.8\n",
      "pciBusID: 0000:1b:00.0\n",
      "2022-06-28 16:05:43.319505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-06-28 16:05:43.322064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-06-28 16:05:43.324208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-06-28 16:05:43.324765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-06-28 16:05:43.327715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-06-28 16:05:43.329802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-06-28 16:05:43.336298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-28 16:05:43.336947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-06-28 16:05:43.337020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-06-28 16:05:43.337517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-28 16:05:43.337541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-06-28 16:05:43.337551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-06-28 16:05:43.338032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/device:GPU:0 with 22499 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1656065515019,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "XGsZO-wr5ayy",
    "outputId": "3c575873-458d-489e-d233-35cf51546112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class CustomConfig(Config):\n",
    "    \"\"\"Configuration for training on the dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"object\"\n",
    "    print( 'hello' )\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 2\n",
    "    IMAGE_RESIZE_MODE = \"square\"\n",
    "    IMAGE_SHAPE = np.array([1024, 1024  ,3])\n",
    "    GPU_COUNT = 1\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 300\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "\n",
    "    LEARNING_RATE = 0.01\n",
    "    DEFAULT_LOGS_DIR=\"/content/drive/MyDrive/PAVE DOUGH DEVELOPMENT (USMAN)/Instance Segmentation Pave/logs\"\n",
    "    ROOT_DIR = os.path.abspath(\"./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/\")\n",
    "    Config.WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "    # CUSTOM_DIR = os.path.join(ROOT_DIR, \"./dataset/\")\n",
    "    DATA_DIR = './datasets/fetch_v1/split_dataset_objects_wise'\n",
    "    colorCodePath = './datasets/old/dataset_v1/labels_mapping.xlsx'\n",
    "    # Directory to save logs and model checkpoints\n",
    "    DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "    IMAGE_MAX_DIM=1024\n",
    "    MAX_GT_INSTANCES=25\n",
    " \n",
    "    #train_subset, val_subset,test_subset = 'training', 'validation','testing'\n",
    "    train_subset, val_subset = 'training', 'validation'\n",
    "    STEPS_PER_EPOCH = int( len(  os.listdir( os.path.join(DATA_DIR, train_subset) ) ) / IMAGES_PER_GPU )-2\n",
    "    VALIDATION_STEPS = int( len(  os.listdir( os.path.join(DATA_DIR, val_subset) ) ) / IMAGES_PER_GPU )-2\n",
    "    #TESTING_STEPS = int( len(  os.listdir( os.path.join(DATA_DIR, test_subset) ) ) / IMAGES_PER_GPU )-2\n",
    "    # classes = ['crack']\n",
    "     # Number of classes (including background)\n",
    "    NUM_CLASSES = 9  # Background + (other labels)\n",
    "    classes = ['conc-slb', 'conc-mrk','conc-crk','conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut','bridge']\n",
    "    # labels_filename = 'labels.json'\n",
    "    json_input_folder_path = './datasets/fetch_v1/split_dataset_objects_wise/jsons'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4424,
     "status": "ok",
     "timestamp": 1656065522476,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "FBvzP3MpbYQz",
    "outputId": "d403ef8c-e5b3-48d9-91cd-bed40e8a81cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DATA_DIR                       ./datasets/fetch_v1/split_dataset_objects_wise\n",
      "DEFAULT_LOGS_DIR               /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/logs\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                21\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.01\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               25\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           object\n",
      "NUM_CLASSES                    9\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "ROOT_DIR                       /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                372\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               160\n",
      "WEIGHTS_PATH                   /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/mask_rcnn_coco.h5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "classes                        ['conc-slb', 'conc-mrk', 'conc-crk', 'conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut', 'bridge']\n",
      "colorCodePath                  ./datasets/old/dataset_v1/labels_mapping.xlsx\n",
      "json_input_folder_path         ./datasets/fetch_v1/split_dataset_objects_wise/jsons\n",
      "train_subset                   training\n",
      "val_subset                     validation\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#%cd /content/drive/MyDrive/PAVE DOUGH DEVELOPMENT (USMAN)/Instance Segmentation Pave\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n",
    "#from config import CustomConfig \n",
    "# Root directory of the project\n",
    "\n",
    "# Import Mask RCNN\n",
    " # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "# Path to trained weights file\n",
    "# sys.path.append(ROOT_DIR) \n",
    "#from dataset_preparation import CustomDataset\n",
    "\n",
    "\n",
    "configs = CustomConfig()\n",
    "(configs.IMAGE_SHAPE)\n",
    "print(configs.display())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzrHUvSBGeIR"
   },
   "outputs": [],
   "source": [
    "# instances_path = '/content/drive/MyDrive/Mask_RCNN/mask_rcnn_instances'\n",
    "\n",
    "# if not os.path.exists(instances_path):\n",
    "#   os.makedirs(instances_path)\n",
    "\n",
    "# !python /content/maskrccn_parse_json.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbDvBcAfec1S"
   },
   "source": [
    "<b> Data Generator to Parse the setup the data streams </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHDTK4L2wVmu"
   },
   "source": [
    "# Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1654113861158,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "2_7WluVPqoLO",
    "outputId": "3d01d618-a882-4449-946a-bcfbfbdc6bd4"
   },
   "outputs": [],
   "source": [
    "configs.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1656065524799,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "KuCPjri29_WZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2, glob\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os,glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "#from config import CustomConfig \n",
    "# Root directory of the project\n",
    "# ROOT_DIR = os.path.abspath(\"./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/\")\n",
    "# Import Mask RCNN\n",
    "# sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "# from mrcnn.config import Config\n",
    "# from mrcnn import model as utils\n",
    "from mrcnn import model as modellib, utils\n",
    "class CustomDataset1(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the Horse-Man dataset.\n",
    "        dataset_dir: Root directory of the dataset.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.configs = CustomConfig()\n",
    "        self.name_dict = {}\n",
    "\n",
    "        df = pd.read_excel( self.configs.colorCodePath )\n",
    "        colorDict = dict(zip(df.Label, df.Color))\n",
    "\n",
    "        classes = self.configs.classes\n",
    "        print(classes, configs.NUM_CLASSES)\n",
    "        count=1\n",
    "        for clas in classes:\n",
    "          self.add_class(\"object\", count, clas)\n",
    "          self.name_dict[clas] = count\n",
    "          count += 1\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        \n",
    "        assert subset in [self.configs.train_subset, self.configs.val_subset]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # annotations1 = json.load(open(os.path.join(dataset_dir, self.configs.labels_filename )))\n",
    "        image_files_list = glob.glob(os.path.join(dataset_dir,'*'))\n",
    "        for index1, path_iter in enumerate(image_files_list):\n",
    "          \n",
    "            num_ids = []\n",
    "            filename = os.path.split(path_iter)[-1]\n",
    "            json_filepath = os.path.join(self.configs.json_input_folder_path, filename.replace('.jpg', '_mask.json'))\n",
    "            file_object = open(json_filepath)\n",
    "            data = json.load(file_object)\n",
    "            data_2 =  data['lsfs']['99']['objects']\n",
    "\n",
    "            json_info, num_ids = self.parse_json(data_2)\n",
    "\n",
    "            # file_iter = os.path.split(path_iter)[-1]\n",
    "            imagepath = path_iter\n",
    "            \n",
    "            image = skimage.io.imread(imagepath)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"object\",  ## for a single class just add the name here\n",
    "                image_id=filename,  # use file name as a unique image id\n",
    "                path= imagepath,\n",
    "                width=width, height=height,\n",
    "                instance_data= json_info,\n",
    "                num_ids=num_ids\n",
    "                )\n",
    "\n",
    "    def parse_json(self, data_2):\n",
    "    \n",
    "        json_info, num_ids =[], []\n",
    "        for i in range(len(data_2)):\n",
    "            curr = {}\n",
    "        # print(i)\n",
    "            if data_2[i]['deleted']==True:\n",
    "              continue\n",
    "            \n",
    "            else:\n",
    "              if data_2[i]['label'] in configs.classes:   #== 'conc-slb':\n",
    "                curr['coordinates'] =data_2[i]['coordinates']\n",
    "                curr['thickness'] = int(data_2[i]['thickness'])\n",
    "                curr['type'] = data_2[i]['type']\n",
    "\n",
    "                curr['label']   = data_2[i]['label']\n",
    "                num_ids.append( self.name_dict[curr['label']] )\n",
    "                json_info.append(curr)\n",
    "                  \n",
    "                  \n",
    "        return json_info, num_ids\n",
    "\n",
    "    def draw_poly(self, img, cordinates, colorCode):\n",
    "        pts = np.array(cordinates, np.int32).reshape((-1, 2))\n",
    "        img=cv2.fillPoly(img, pts=[pts],  color=colorCode )\n",
    "\n",
    "        return img\n",
    "\n",
    "    def draw_instance(self, mask, curr):\n",
    "          \n",
    "          # print(curr['label'], self.configs.classes)\n",
    "          if curr['label'] in self.configs.classes:\n",
    "              # print(curr)\n",
    "              if curr['type'] == 'Polygon':\n",
    "                  mask = self.draw_poly(mask, curr['coordinates'], 1)\n",
    "          \n",
    "              else:\n",
    "                  for k in range(len(curr['coordinates'])-1):   \n",
    "                    # print(k, curr['coordinates'][k], curr['coordinates'][k+1])\n",
    "                    mask = cv2.line(mask, pt1=tuple(curr['coordinates'][k]), pt2=tuple(curr['coordinates'][k+1]), color=(1,1), thickness= curr['thickness'] )\n",
    "\n",
    "          return mask\n",
    "    \n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a Horse/Man dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Convert polygons to a bitmap mask of shape\n",
    "        # [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] != \"object\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        # print('info', info)\n",
    "        num_ids = info['num_ids']\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"instance_data\"])],dtype=np.uint8)\n",
    "        \n",
    "        for i, p in enumerate(info[\"instance_data\"]):\n",
    "          # Get indexes of pixels inside the polygon and set them to 1\n",
    "          single_mask = np.zeros( (info[\"height\"], info[\"width\"]), dtype=np.uint8)\n",
    "          single_mask = self.draw_instance(single_mask, p)\n",
    "          # rr, cc = skimage.draw.polygon(np.array(p['all_points_y'])-1, np.array(p['all_points_x'])-1)\n",
    "          # rgb = np.dstack((single_mask,single_mask,single_mask))\n",
    "          # rgb_resized = cv2.resize(rgb.astype('uint8'),(1024,1024))\n",
    "\n",
    "          mask[:, :, i] = single_mask\n",
    "          \n",
    "        # from google.colab.patches import cv2_imshow\n",
    "        # print(img.shape)\n",
    "        # cv2_imshow(img)\n",
    "        # break\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        # Map class names to class IDs.\n",
    "        num_ids = np.array(num_ids, dtype=np.int32)\n",
    "        # print(mask.shape, num_ids.shape)\n",
    "        # print(image_info )\n",
    "        return mask, num_ids #np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"object\":\n",
    "            # print(info['path'])\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42702,
     "status": "ok",
     "timestamp": 1653480330638,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "v5XXbsrAZAjq",
    "outputId": "17afe4c7-d5f8-4945-c68f-f1e2e7f5bdfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conc-slb', 'conc-mrk', 'conc-crk', 'conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut', 'bridge'] 9\n",
      "(3381, 2150, 6) [4 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_train = CustomDataset1()\n",
    "dataset_train.load_custom(configs.DATA_DIR, \"training\")\n",
    "# print(configs.DATA_DIR)\n",
    "dataset_train.prepare()\n",
    "\n",
    "mask = dataset_train.load_mask(1)\n",
    "print(mask[0].shape, mask[1])\n",
    "\n",
    "# # file_name = os.path.split(dataset_train.image_reference(k) )[-1]\n",
    "\n",
    "# final_mask = np.zeros( ( mask[0].shape[:2] + (3,) ) )\n",
    "# colorcodes = []\n",
    "# for i in range( mask[0].shape[2] ):\n",
    "\n",
    "#   instance1 = mask[0][:,:, i]\n",
    "#   colorcodes.append(tuple( np.random.randint(256, size=3) ))\n",
    "#   final_mask[instance1==1] = colorcodes[-1]\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# cv2_imshow(final_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1652995761348,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "rmpxvr1_3Y79",
    "outputId": "cb8a2563-e2f8-45d6-e1c0-e6a69f720da9"
   },
   "outputs": [],
   "source": [
    "np.unique(mask[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "executionInfo": {
     "elapsed": 594,
     "status": "error",
     "timestamp": 1655649369643,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "FzGy_M0F3ilU",
    "outputId": "f6a42c2c-2c52-43c1-c5ac-11d7cd811f9f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask[0][:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1653480172226,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "0L6MeGHYd__e",
    "outputId": "bb795065-a553-40ea-ccb1-49fffdf35f49"
   },
   "outputs": [],
   "source": [
    "#for _id_iter in (range(len(dataset_train.image_ids))):\n",
    "image_id = 10\n",
    "print(image_id)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_train, configs, image_id, use_mini_mask=False)\n",
    "print(gt_mask.shape,image.shape)\n",
    "print(gt_class_id)\n",
    "  # info = dataset_val.image_info[image_id]\n",
    "  # print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,dataset_val.image_reference(image_id)))\n",
    "  # # Run object detection\n",
    "  # results = model.detect([image], verbose=1)\n",
    "  # # Display results\n",
    "  # x = get_ax(1)\n",
    "  # r = results[0]\n",
    "  # visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset_val.class_names, r['scores'], ax=x, title=\"Predictions\")\n",
    "  # plt.savefig(os.path.join(outputpath_results,str(_id_iter)+'.jpg'), dpi='figure')\n",
    "  # log(\"gt_class_id\", gt_class_id)\n",
    "  # log(\"gt_bbox\", gt_bbox)\n",
    "  # log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1653480081115,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "nVubLxY-qTX3",
    "outputId": "e81a2c9c-28b9-4349-d1aa-b309b7923710"
   },
   "outputs": [],
   "source": [
    "plt.imshow(gt_mask[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 963,
     "status": "ok",
     "timestamp": 1653480177467,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "MCR5CZoxDWkT",
    "outputId": "a0137101-315b-4613-c574-e6390ed44123"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYtd8NaXOuTU"
   },
   "outputs": [],
   "source": [
    "# base_dir = './masks'\n",
    "# #finding countours and bounding boxes\n",
    "# def find_contours(img):\n",
    "    \n",
    "#     img = np.where(img==(54,  67, 244),255,0)\n",
    "#     result = np.array(img).astype('uint8')\n",
    "    \n",
    "#     contours = cv2.findContours(np.array(img[:,:,0]).astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "#     for cntr in contours[:1]:\n",
    "#         # cntr1 = cntr\n",
    "#         # exit()\n",
    "#         x,y,w,h = cv2.boundingRect(cntr)\n",
    "#         cv2.rectangle(result, (x, y), (x+w, y+h), (255, 255, 255), 32)\n",
    "#         print(\"x,y,w,h:\",x,y,w,h)\n",
    "\n",
    "#     # print(result)\n",
    "#     return result\n",
    "# # plt.imshow(result)\n",
    "\n",
    "# # Validation dataset\n",
    "# dataset_train = CustomDataset()\n",
    "# dataset_train.load_custom(configs.DATA_DIR, \"training\")\n",
    "# # print(configs.DATA_DIR)\n",
    "# dataset_train.prepare()\n",
    "\n",
    "# for k in range(300):\n",
    "\n",
    "#   mask = dataset_train.load_mask(k)[0]\n",
    "#   file_name = os.path.split(dataset_train.image_reference(k) )[-1]\n",
    "\n",
    "#   final_mask = np.zeros( ( mask.shape[:2] + (3,) ) )\n",
    "#   colorcodes = []\n",
    "#   for i in range( mask.shape[2] ):\n",
    "\n",
    "#     instance1 = mask[:,:, i]\n",
    "#     colorcodes.append(tuple( np.random.randint(256, size=3) ))\n",
    "#     final_mask[instance1==1] = colorcodes[-1]\n",
    "\n",
    "#     cv2.imwrite(os.path.join(base_dir, f'mask_{file_name}' ), final_mask )\n",
    "#     img = cv2.imread(dataset_val.image_reference(i))\n",
    "\n",
    "#     contr_filename = file_name.replace('.jpg', '.png')\n",
    "#     print(contr_filename)\n",
    "#     # /content/final data/masks/201021_155645975_Camera_7.png\n",
    "#     contr_mask = cv2.imread(f'/content/final data/masks/{contr_filename}')\n",
    "#     result = find_contours( contr_mask ) \n",
    "#     cv2.imwrite( os.path.join(base_dir, f'{file_name}' ), img )\n",
    "#     # print(result.shape)\n",
    "#     a = cv2.imwrite(os.path.join(base_dir, f'contour_{file_name}' ), result )\n",
    "#     print(a)\n",
    "#     # plt.imsave(os.path.join(base_dir, f'contour_{file_name}' ), result)\n",
    "#   # print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h39NYO1wbm_"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AqfsEGQ0fVfr"
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = CustomDataset1()\n",
    "    dataset_train.load_custom(configs.DATA_DIR, \"training\")\n",
    "    # print(configs.DATA_DIR)\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CustomDataset1()\n",
    "    dataset_val.load_custom(configs.DATA_DIR, \"validation\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train,dataset_val,\n",
    "                learning_rate=configs.LEARNING_RATE,\n",
    "                \n",
    "                epochs=25,\n",
    "                layers='3+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75663,
     "status": "ok",
     "timestamp": 1655668986215,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "uj4D9sKUf2Kk",
    "outputId": "8ca0d181-78eb-4964-d209-f9b281f4fe3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1768: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:158: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:163: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:333: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:341: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:07:11.289410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 major: 8 minor: 6 memoryClockRate(GHz): 1.8\n",
      "pciBusID: 0000:1b:00.0\n",
      "2022-06-28 16:07:11.289498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-06-28 16:07:11.289525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-06-28 16:07:11.289548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-06-28 16:07:11.289570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-06-28 16:07:11.289591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-06-28 16:07:11.289613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-06-28 16:07:11.289634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-28 16:07:11.290181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-06-28 16:07:11.290227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-28 16:07:11.290244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-06-28 16:07:11.290255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-06-28 16:07:11.290873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22499 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1b:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conc-slb', 'conc-mrk', 'conc-crk', 'conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut', 'bridge'] 9\n",
      "['conc-slb', 'conc-mrk', 'conc-crk', 'conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut', 'bridge'] 9\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.01\n",
      "\n",
      "Checkpoint Path: /home/yun-lab/usman projects/PAVE dOUGH PROJECT/INSTANCE SEGMENTATION MODELING/MASKRCNN/Training1/wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/logs/object20220628T1611/mask_rcnn_object_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/optimizers.py:711: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:899: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:625: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:886: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yun-lab/anaconda3/envs/maskcrcnn_fastapi/lib/python3.7/site-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 16:13:39.633425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-06-28 16:14:49.764764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-28 16:29:17.399896: W tensorflow/stream_executor/cuda/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# config = CustomConfig()\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=configs,\n",
    "                                  model_dir=configs.DEFAULT_LOGS_DIR)\n",
    "\n",
    "weights_path = configs.WEIGHTS_PATH\n",
    "# weights_path = \"./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/logs/object20220412T0723/mask_rcnn_object_0014.h5\"\n",
    "        # Download weights file\n",
    "if not os.path.exists(weights_path):\n",
    "  utils.download_trained_weights(weights_path)\n",
    "\n",
    "\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJdHYrV4qYPt"
   },
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efj4YVV9lxNU"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import random\n",
    "# import math\n",
    "# import re\n",
    "# import time\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import matplotlib.image as mpimg\n",
    "# # Root directory of the project\n",
    "# #ROOT_DIR = os.path.abspath(\"/\")\n",
    "\n",
    "# # Import Mask RCNN\n",
    "# sys.path.append(configs.ROOT_DIR)  # To find local version of the library\n",
    "# from mrcnn import utils\n",
    "# from mrcnn import visualize\n",
    "# from mrcnn.visualize import display_images\n",
    "# import mrcnn.model as modellib\n",
    "# from mrcnn.model import log\n",
    "# %matplotlib inline\n",
    "# # Directory to save logs and trained model\n",
    "# MODEL_DIR = os.path.join(configs.ROOT_DIR, \"logs\")\n",
    "# # Path to Ballon trained weights\n",
    "# # You can download this file from the Releases page\n",
    "# # https://github.com/matterport/Mask_RCNN/releases\n",
    "# WEIGHTS_PATH = \"./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/logs/object20220519T2226/mask_rcnn_object_0006.h5\"  # TODO: update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1656065538659,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "ufdPnpKyqzXe",
    "outputId": "f59ec639-75b6-41f2-fbe2-ba9bf481a267"
   },
   "outputs": [],
   "source": [
    "configs = CustomConfig()\n",
    "CUSTOM_DIR = os.path.join(configs.ROOT_DIR, configs.DATA_DIR)\n",
    "class InferenceConfig(configs.__class__):\n",
    "  # Run detection on one image at a time\n",
    "  GPU_COUNT = 1\n",
    "  IMAGES_PER_GPU = 1\n",
    "  #STEPS_PER_EPOCHS=10\n",
    "  DETECTION_MIN_CONFIDENCE = 0.6\n",
    "\n",
    "configs_infer = InferenceConfig()\n",
    "configs_infer.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42822,
     "status": "ok",
     "timestamp": 1656065585347,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "fPPKAygyzgFE",
    "outputId": "a0e68f8d-8110-4d8a-eaa2-82a69cc63ae2"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "# Inspect the model in training or inference modes values: 'inference' or 'training'\n",
    "TEST_MODE = \"inference\"\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "  # \"\"Return a Matplotlib Axes array to be used in all visualizations in the notebook. Provide a central point to control graph sizes. Adjust the size attribute to control how big to render images\"\"\"\n",
    "  _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "  return ax\n",
    "\n",
    "# Load validation dataset\n",
    "\n",
    "dataset_val = CustomDataset1()\n",
    "dataset_val.load_custom(configs.DATA_DIR, \"validation\")\n",
    "# print(configs.DATA_DIR)\n",
    "dataset_val.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset_val.image_ids), dataset_val.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vtx_hpgqs_R"
   },
   "source": [
    "## **Loading model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9568,
     "status": "ok",
     "timestamp": 1656065594893,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "ZdehD8DZ0G3U",
    "outputId": "d7855add-e612-4647-b707-97712883b1c8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "# Inspect the model in training or inference modes values: 'inference' or 'training'\n",
    "TEST_MODE = \"inference\"\n",
    "with tf.device(DEVICE):\n",
    "  model = modellib.MaskRCNN(mode=\"inference\", model_dir=configs.DEFAULT_LOGS_DIR, config=configs_infer)\n",
    "\n",
    "#weights_path = WEIGHTS_PATH\n",
    "weights_path = \"./wastedata-Mask_RCNN-multiple-classes/main/Mask_RCNN/logs/object20220619T1446/mask_rcnn_object_0022.h5\"\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hTVQT-w20P5D"
   },
   "outputs": [],
   "source": [
    "# from mrcnn import utils\n",
    "# from mrcnn import visualize\n",
    "# #from mrcnn.visualize import display_images\n",
    "# import mrcnn.model as modellib\n",
    "# from mrcnn.model import log\n",
    "\n",
    "# output_path = '/content/drive/MyDrive/PAVE DOUGH DEVELOPMENT (USMAN)/Instance Segmentation Pave'\n",
    "# outputpath_results = os.path.join(output_path,'slb-mark-crck_results')\n",
    "# if not os.path.exists(outputpath_results):\n",
    "#   os.makedirs(outputpath_results)\n",
    "\n",
    "# def get_ax(rows=1, cols=1, size=16):\n",
    "#   # \"\"Return a Matplotlib Axes array to be used in all visualizations in the notebook. Provide a central point to control graph sizes. Adjust the size attribute to control how big to render images\"\"\"\n",
    "#   _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "#   return ax\n",
    "\n",
    "# for _id_iter in (range(len(dataset_val.image_ids))):\n",
    "#   image_id = _id_iter\n",
    "#   print(image_id)\n",
    "#   image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "#     modellib.load_image_gt(dataset_val, configs, image_id, use_mini_mask=False)\n",
    "\n",
    "#   info = dataset_val.image_info[image_id]\n",
    "#   print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id,dataset_val.image_reference(image_id)))\n",
    "#   # Run object detection\n",
    "#   results = model.detect([image], verbose=1)\n",
    "#   # Display results\n",
    "#   x = get_ax(1)\n",
    "#   r = results[0]\n",
    "#   visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], dataset_val.class_names, r['scores'], ax=x, title=\"Predictions\")\n",
    "#   plt.savefig(os.path.join(outputpath_results,str(_id_iter)+'.jpg'), dpi='figure')\n",
    "#   log(\"gt_class_id\", gt_class_id)\n",
    "#   log(\"gt_bbox\", gt_bbox)\n",
    "#   log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VwU83zGq09q"
   },
   "source": [
    "## **Saving model prediction 3in1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1656065594896,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "gCGNCnsPchNa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import colorsys\n",
    "\n",
    "import numpy as np\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches,  lines\n",
    "from matplotlib.patches import Polygon\n",
    "import IPython.display\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "\n",
    "def display_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None,\n",
    "                      show_mask=True, show_bbox=True,\n",
    "                      colors=None, captions=None):\n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    title: (optional) Figure title\n",
    "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "    figsize: (optional) the size of the image\n",
    "    colors: (optional) An array or colors to use with each object\n",
    "    captions: (optional) A list of strings to use as captions for each object\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to display *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "    auto_show = False\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "        auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    # ax.set_ylim(height + 10, -10)\n",
    "    # ax.set_xlim(-10, width + 10)\n",
    "    # ax.axis('off')\n",
    "    # ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    \n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                                alpha=0.7, linestyle=\"dashed\",\n",
    "                                edgecolor=color, facecolor='none')\n",
    "            #ax.add_patch(p)\n",
    " \n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:\n",
    "            masked_image = apply_mask(masked_image, mask, color)\n",
    "        \n",
    "        x_loc = int(x1+((x2-x1)/2))\n",
    "        y_loc = int(y1+((y2-y1)/2))\n",
    "        text_list = [class_names[class_id],str(int(round(scores[i],2)*100))+'%']\n",
    "        for counter1 in range(2):\n",
    "          if (int(width) - int(x_loc)) < 300:\n",
    "            x_loc = int(width)-300\n",
    "          if (int(height) - int(y_loc)) < 200:\n",
    "            y_loc = int(height)-300\n",
    "          \n",
    "          masked_image = cv2.putText(masked_image.astype('uint8'), text_list[counter1], (x_loc,y_loc), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX,2, (255,255,255), 2, cv2.LINE_AA)\n",
    "          y_loc = y_loc+55\n",
    "          x_loc = x_loc+30\n",
    "    return masked_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1656065594898,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "PwiFuKaurOM1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, os, json\n",
    "from PIL import ImageColor\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os,glob\n",
    "\n",
    "def color_code_dict(csv_path):\n",
    "  \n",
    "  df=pd.read_excel(csv_path)\n",
    "  return dict(zip(df.Label, df.Color))\n",
    "# color_dict\n",
    "\n",
    "def draw_poly(img, cordinates, colorCode):\n",
    "  pts = np.array(cordinates, np.int32).reshape((-1, 2))\n",
    "  img=cv2.fillPoly(img, pts=[pts],  color=colorCode )\n",
    "\n",
    "  return img\n",
    "\n",
    "def create_mask(data_2, colorDict,imgsize):\n",
    "  h,w = imgsize#(3483,2149)\n",
    "  mask = np.ones((h,w, 3)) * 255\n",
    "  mask =  mask.astype('uint8')\n",
    "  for i in range(len(data_2)):\n",
    "    # print(i)\n",
    "    if data_2[i]['deleted']==True:\n",
    "      colors = [255,255,255]\n",
    "    else:\n",
    "      colors = colorDict[ data_2[i]['label'] ]\n",
    "      colors = ImageColor.getcolor('#'+str(colors), \"RGB\")\n",
    "      #if label is conc-slb\n",
    "      # if data_2[i]['label'] == 'conc-slb':\n",
    "      #   colors = ()\n",
    "      #print(colors)\n",
    "      \n",
    "\n",
    "    \n",
    "    curr=data_2[i]['coordinates']\n",
    "    colorCode = [colors[2], colors[1], colors[0]]#,100]\n",
    "\n",
    "    thickness = int(data_2[i]['thickness'])\n",
    "    if data_2[i]['type'] == 'Polygon':\n",
    "      mask = draw_poly(mask, curr, colorCode)\n",
    "\n",
    "    else:\n",
    "      for k in range(len(curr)-1):\n",
    "\n",
    "        mask = cv2.line(mask, pt1=tuple(curr[k]), pt2=tuple(curr[k+1]), color=colorCode, thickness= thickness )\n",
    " \n",
    "  return mask\n",
    "\n",
    "\n",
    "def overlay_3in1_mask(image,mask):\n",
    "\n",
    "    output = cv2.addWeighted(mask, 0.6, image, 1, 0)\n",
    "    im_v = cv2.hconcat([image,output, mask])\n",
    "    return im_v\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == True,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAdljIyeJ9S2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "sys.path.append(configs.ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "#from mrcnn import visualize\n",
    "#from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "dataset_basepath  = 'datasets/fetch_v1/split_dataset_objects_wise'\n",
    "\n",
    "json_path=os.path.join(dataset_basepath,'jsons')\n",
    "\n",
    "\n",
    "colorcode_file_path = r'labels_mapping.xlsx'\n",
    "\n",
    "color_dict = color_code_dict(colorcode_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# This is for predicting images which are not present in dataset\n",
    "output_path = './results/fetch_v1_val_10chk'\n",
    "outputpath_results = os.path.join(output_path,'all_class_testing')\n",
    "if not os.path.exists(outputpath_results):\n",
    "  os.makedirs(outputpath_results)\n",
    "\n",
    "imgs_name = os.listdir(os.path.join(dataset_basepath,'validation'))#'./datasets/dataset_v2/testing')\n",
    "print(\"Total images found in the folder: \",len(imgs_name))\n",
    "for k in range(len(imgs_name)):\n",
    "  path_to_new_image = os.path.join(dataset_basepath,'validation',imgs_name[k])\n",
    "  orig_img = cv2.imread(path_to_new_image)\n",
    "  print(orig_img.shape)\n",
    "  image1 = mpimg.imread(path_to_new_image)\n",
    "  print(image1.shape)\n",
    "  results1 = model.detect([image1], verbose=1)\n",
    "  # Display results\n",
    "  ax1 = get_ax(1)\n",
    "  r1 = results1[0]\n",
    "  masked_img = display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'], \\\n",
    "                                dataset_val.class_names, r1['scores'], ax=ax1, title=\"Predictions1\")\n",
    "  \n",
    "\n",
    "  #applying ground truth\n",
    "  imagesize = orig_img.shape[:2]\n",
    "  file_object = open(os.path.join(json_path, imgs_name[k].split('.')[0]+'_mask.json'))\n",
    "\n",
    "\n",
    "  data = json.load(file_object)\n",
    "  data_2 =  data['lsfs']['99']['objects']\n",
    "  #print(file_path)\n",
    "  mask = create_mask(data_2, color_dict,imagesize)\n",
    "  orig_image1 = orig_img.copy()\n",
    "  colors_list = random_colors(len(list(color_dict.keys())))\n",
    "  #print(color_dict.keys())\n",
    "\n",
    "  for index1,key_iter in enumerate(color_dict.keys()):\n",
    "      color = ImageColor.getcolor('#'+str(color_dict[key_iter]), \"RGB\")\n",
    "      #print(\"inner lopp\")\n",
    "      #print([color[2],color[1],color[0]])\n",
    "      #mask1 = np.where(mask == [color[2],color[1],color[0]],255,0)\n",
    "      \n",
    "      mask1 = np.all(mask.astype('uint8') == [color[2],color[1],color[0]], axis=-1)\n",
    "      \n",
    "      orig_image1 = apply_mask(orig_image1, mask1, colors_list[index1], alpha=0.5)\n",
    "      #orig_image1 = apply_mask(orig_image1, mask1, (color[2],color[1],color[0]), alpha=0.5)\n",
    "\n",
    "\n",
    "  #print(\"outside inner loop\")\n",
    "  stakced = np.hstack((orig_image1,orig_img,masked_img))\n",
    "  plt.imshow(stakced)\n",
    "  check = cv2.imwrite(os.path.join(outputpath_results,imgs_name[k]),stakced.astype('uint8'))\n",
    "  #print(\"check:\",check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3777,
     "status": "ok",
     "timestamp": 1655125629705,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "cgFQsO28rOU2",
    "outputId": "694511eb-4e24-468f-baa8-9a3a69715c9a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "sys.path.append(configs.ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "#from mrcnn import visualize\n",
    "#from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "colorcode_file_path = r'labels_mapping.xlsx'\n",
    "json_path=r'datasets/dataset_v2/jsons'\n",
    "color_dict = color_code_dict(colorcode_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# This is for predicting images which are not present in dataset\n",
    "output_path = './results/dataset_v2'\n",
    "outputpath_results = os.path.join(output_path,'all_class_testing')\n",
    "if not os.path.exists(outputpath_results):\n",
    "  os.makedirs(outputpath_results)\n",
    "\n",
    "imgs_name = os.listdir('./datasets/dataset_v2/testing')\n",
    "print(\"Total images found in the folder: \",len(imgs_name))\n",
    "for k in range(len(imgs_name)):\n",
    "  path_to_new_image = os.path.join(f'./datasets/dataset_v2/testing/{imgs_name[k]}')\n",
    "  orig_img = cv2.imread(path_to_new_image)\n",
    "  print(orig_img.shape)\n",
    "  image1 = mpimg.imread(path_to_new_image)\n",
    "  print(image1.shape)\n",
    "  results1 = model.detect([image1], verbose=1)\n",
    "  # Display results\n",
    "  ax1 = get_ax(1)\n",
    "  r1 = results1[0]\n",
    "  masked_img = display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'], \\\n",
    "                                dataset_val.class_names, r1['scores'], ax=ax1, title=\"Predictions1\")\n",
    "  print(masked_img.shape)\n",
    "  break\n",
    "  #applying ground truth\n",
    "  imagesize = orig_img.shape[:2]\n",
    "  file_object = open(os.path.join(json_path, imgs_name[k].split('.')[0]+'_mask.json'))\n",
    "\n",
    "\n",
    "  data = json.load(file_object)\n",
    "  data_2 =  data['lsfs']['99']['objects']\n",
    "  #print(file_path)\n",
    "  mask = create_mask(data_2, color_dict,imagesize)\n",
    "  orig_image1 = orig_img.copy()\n",
    "  colors_list = random_colors(len(list(color_dict.keys())))\n",
    "  print(color_dict.keys())\n",
    "\n",
    "  for index1,key_iter in enumerate(color_dict.keys()):\n",
    "      color = ImageColor.getcolor('#'+str(color_dict[key_iter]), \"RGB\")\n",
    "      print(\"inner lopp\")\n",
    "      #print([color[2],color[1],color[0]])\n",
    "      #mask1 = np.where(mask == [color[2],color[1],color[0]],255,0)\n",
    "      \n",
    "      mask1 = np.all(mask.astype('uint8') == [color[2],color[1],color[0]], axis=-1)\n",
    "      \n",
    "      orig_image1 = apply_mask(orig_image1, mask1, colors_list[index1], alpha=0.5)\n",
    "      #orig_image1 = apply_mask(orig_image1, mask1, (color[2],color[1],color[0]), alpha=0.5)\n",
    "\n",
    "\n",
    "  print(\"outside inner loop\")\n",
    "  stakced = np.hstack((orig_image1,orig_img,masked_img))\n",
    "  plt.imshow(stakced)\n",
    "  check = cv2.imwrite(os.path.join(outputpath_results,imgs_name[k]),stakced.astype('uint8'))\n",
    "  print(\"check:\",check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1654296065948,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "0-D7NkFErOdA",
    "outputId": "75aa4bad-af71-4c23-8fdc-6e5dba5a9497"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO0EgtW3-Pda"
   },
   "source": [
    "<b> Prediction on any single image </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8428,
     "status": "ok",
     "timestamp": 1656065737424,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "sd_pdWnzfHFI",
    "outputId": "4dca8806-5d5b-485c-c979-cf470d0c0ea3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "path_to_new_image = '/content/crack_38.jpg'\n",
    "image1 = mpimg.imread(path_to_new_image)\n",
    "results1 = model.detect([image1], verbose=1)\n",
    "ax1 = get_ax(1)\n",
    "r1 = results1[0]\n",
    "print(r1['class_ids'])\n",
    "maskedimg = display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'], \\\n",
    "                            dataset_val.class_names, r1['scores'], ax=ax1, title=\"Predictions1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1656066591968,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "Gs0FXu6-kqmG",
    "outputId": "29ec0ae0-6ff1-4af2-b456-04f9dda3b501"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1655993593428,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "LlTMXA_gg_V-",
    "outputId": "9f57050f-787d-4298-b851-7b479cb31480"
   },
   "outputs": [],
   "source": [
    "plt.imshow(masks1[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1656065908108,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "j26aQXV6OFYt",
    "outputId": "9d7aa1d5-a9af-4131-abe0-0807c467bd4e"
   },
   "outputs": [],
   "source": [
    "len(r1['class_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1656072462011,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "y4K5tMm46bK3",
    "outputId": "48888517-fe1e-4785-e9f1-1a1be133b764"
   },
   "outputs": [],
   "source": [
    "from PIL import ImageColor\n",
    "import json\n",
    "\n",
    "model_classes = ['conc-slb', 'conc-mrk','conc-crk','conc-msk-long-ltrt', 'conc-spl', 'conc-pat', 'conc-cut','bridge']\n",
    "\n",
    "def populate_json(objects_list):\n",
    "  jsons1 = {\n",
    "    \"version\": \"v1.0\",\n",
    "    \"lsfs\":{\n",
    "        \"300\": {\n",
    "            \"id\": 300,\n",
    "            \"name\": \"alg\",\n",
    "            \"objects\": objects_list}\n",
    "            }\n",
    "         }\n",
    "  return jsons1\n",
    "\n",
    "def populate_objects(objects_list , dict1):\n",
    "  objects1 = {\n",
    "      \"id\": dict1['id'],\n",
    "      \"type\": \"Polygon\",\n",
    "      \"date\": \"date\",\n",
    "      \"isLabeled\": 'true',\n",
    "      \"deleted\": 'false',\n",
    "      \"class\": dict1['class_label'],\n",
    "      \"thickness\": \"10\",\n",
    "      \"hasOutline\": True,\n",
    "      \"coordinates\": dict1['cords'],\n",
    "      \"doughCode\":dict1['dough_code'], #\"12-C00\",\n",
    "      \"label\": dict1['class_label'],#\"asph-crk\",\n",
    "      \"labelColor\": dict1['hexa_color'],#\"#f44336\",\n",
    "      \"labelRgbColor\": {\n",
    "          \"r\": dict1['rgb_color'][0],\n",
    "          \"g\": dict1['rgb_color'][0],\n",
    "          \"b\": dict1['rgb_color'][0]\n",
    "          },\n",
    "        }\n",
    "  objects_list.append(objects1)\n",
    "  return objects_list\n",
    "\n",
    "def write_json(jsons1,path1):\n",
    "  completeName = '/content/crack_38_mask.json'\n",
    "  with open(path1, \"w\") as outfile:\n",
    "    json.dump(jsons1, outfile)\n",
    "\n",
    "def color_code_dict(csv_path):\n",
    "  df=pd.read_csv(csv_path,header=None)\n",
    "  a = zip(df.iloc[:,0].values.tolist(), df.iloc[:,1].values.tolist(),df.iloc[:,2].values.tolist())\n",
    "  dict1 = {}\n",
    "  for index1,i in enumerate(list(a)):\n",
    "    dict1[list(i)[0]] = {'hexa_color':list(i)[1],'dough_code':list(i)[2]}\n",
    "\n",
    "  return dict1\n",
    "\n",
    "\n",
    "def get_json(results1,labels_dict,json_path1):\n",
    "  \n",
    "  if len(results1['class_ids']) > 0:\n",
    "\n",
    "    #finding predicted classes\n",
    "    predicted_classes = [model_classes[i-1] for i in results1['class_ids']]\n",
    "\n",
    "    masks1 = results1['masks']\n",
    "    objects_list = []\n",
    "    #iterating over predicted masks\n",
    "    for maskIndex_iter in range(masks1.shape[-1]):\n",
    "      binary_mask = masks1[:,:,maskIndex_iter].astype('uint8') \n",
    "\n",
    "      #finding contours\n",
    "      contours, hierarchy = cv2.findContours(binary_mask, \n",
    "                                             cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "      #Converting contours in polygons\n",
    "      if len(contours[0]) >= 2:\n",
    "        \n",
    "        contours = np.reshape(contours[0],(-1,2))\n",
    "        polygons1 = []\n",
    "        for cord_iter in contours:\n",
    "          polygons1.append( [ int(cord_iter[0]) , int(cord_iter[1])  ])\n",
    "        polygons1.append([polygons1[0][0],polygons1[0][1]])\n",
    "        \n",
    "        dict1={}\n",
    "        dict1['id'] = int(results1['class_ids'][maskIndex_iter]) \n",
    "        dict1['class_label'] = predicted_classes[maskIndex_iter]\n",
    "        dict1['cords'] = polygons1\n",
    "        dict1['dough_code'] = labels_dict[predicted_classes[maskIndex_iter]]['dough_code']\n",
    "        dict1['hexa_color'] = labels_dict[predicted_classes[maskIndex_iter]]['hexa_color']\n",
    "        dict1['rgb_color'] = ImageColor.getcolor(labels_dict[predicted_classes[maskIndex_iter]]['hexa_color'], \"RGB\")\n",
    "        print(dict1['class_label'],dict1['id'],dict1['rgb_color'],dict1['dough_code'],dict1['hexa_color'])\n",
    "        objects_list = populate_objects(objects_list , dict1) \n",
    "    \n",
    "    jsons1 = populate_json(objects_list)\n",
    "    write_json(jsons1,json_path1)\n",
    "    \n",
    "        \n",
    "csv_path = r'/content/labels_instance.csv'\n",
    "json_path1 = '/content/crack_38_mask.json'    \n",
    "labels_dict = color_code_dict(csv_path)\n",
    "get_json(r1,labels_dict,json_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1656066040578,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "7vSq_XpNOYz8",
    "outputId": "147b172c-be28-4992-cee2-0053139414db"
   },
   "outputs": [],
   "source": [
    "_masks1 = r1['masks']\n",
    "binary_mask = masks1[:,:,0].astype('uint8') \n",
    "contours, hierarchy = cv2.findContours(binary_mask, \n",
    "                                             cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "contours[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1656003236407,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "vsL2DWK-657I",
    "outputId": "acdbc908-79be-45f8-bfb8-7f7cf3f200d6"
   },
   "outputs": [],
   "source": [
    "a = np.reshape(contours[0],(-1,2))\n",
    "c = []\n",
    "for i in a:\n",
    "  b=[]\n",
    "  b.append(int(i[0]))\n",
    "  b.append(int(i[1]))\n",
    "  c.append(b)\n",
    "c.append([c[0][0],c[0][1]])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oetUzE0XgCAY"
   },
   "outputs": [],
   "source": [
    "\"id\": 0,\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"date\": \"\",\n",
    "                    \"isLabeled\": true,\n",
    "                    \"deleted\": false,\n",
    "                    \"doughCode\": \"11-910\",\n",
    "                    \"label\": \"conc-msk-long-ltrt\",\n",
    "                    \"labelColor\": \"#000000\",\n",
    "                    \"labelRgbColor\": {\n",
    "                        \"r\": 0,\n",
    "                        \"g\": 0,\n",
    "                        \"b\": 0\n",
    "                    },\n",
    "                    \"thickness\": 1,\n",
    "                    \"class\": \"none\",\n",
    "                    \"coordinates\": ["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERDZni74-n4S"
   },
   "outputs": [],
   "source": [
    " objects = {\n",
    "     \"id\": 75,\n",
    "     \"type\": \"Polygon\",\n",
    "     \"date\": \"date\",\n",
    "     \"isLabeled\": 'true',\n",
    "     \"deleted\": 'false',\n",
    "     \"class\": \"\",\n",
    "     \"thickness\": \"1\",\n",
    "     \"hasOutline\": False,\n",
    "     \"coordinates\": c,\n",
    "     \"doughCode\": \"12-C00\",\n",
    "     \"label\": \"asph-crk\",\n",
    "     \"labelColor\": \"#f44336\",\n",
    "     \"labelRgbColor\": {\n",
    "         \"r\": 244,\n",
    "         \"g\": 67,\n",
    "         \"b\": 54\n",
    "         },\n",
    "        }\n",
    "obj_list = []\n",
    "obj_list.append(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O04BKhfJ-w8B"
   },
   "outputs": [],
   "source": [
    "jsons = {\n",
    "    \"version\": \"v1.0\",\n",
    "    \"lsfs\":{\n",
    "        \"200\": {\n",
    "            \"id\": 200,\n",
    "            \"name\": \"alg\",\n",
    "            \"objects\": obj_list}\n",
    "            }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llnmXhtz_Lvu"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "completeName = '/content/crack_38_mask.json'\n",
    "with open(completeName, \"w\") as outfile:\n",
    "    json.dump(jsons, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "error",
     "timestamp": 1656003250548,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "Kl1-Unz2MOG6",
    "outputId": "e2deefa9-34c3-46ee-ae0c-363ee18ac545"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "jsonpath = '/content/crack_11_mask.json'\n",
    "file_object = open(file_iter)\n",
    "data = json.load(file_object)\n",
    "data_2 =  data['lsfs']['99']['objects']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yjr1_qTvrB_y"
   },
   "source": [
    "## **Prediction 2in1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "14ECvrSghFIQbamDe-jvfofAASFvl6giV"
    },
    "executionInfo": {
     "elapsed": 633779,
     "status": "ok",
     "timestamp": 1654150218292,
     "user": {
      "displayName": "Usman Ali",
      "userId": "15116480744776549162"
     },
     "user_tz": -300
    },
    "id": "x8T-o42O2Dw-",
    "outputId": "d9bef22b-9635-474b-ea38-f641fcbc4b35"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "# Root directory of the project\n",
    "#ROOT_DIR = os.path.abspath(\"/\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(configs.ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "#from mrcnn import visualize\n",
    "#from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "\n",
    "# This is for predicting images which are not present in dataset\n",
    "output_path = '/content/drive/MyDrive/PAVE DOUGH DEVELOPMENT (USMAN)/Instance Segmentation Pave/results/dataset_v2'\n",
    "outputpath_results = os.path.join(output_path,'all_class_validation')\n",
    "if not os.path.exists(outputpath_results):\n",
    "  os.makedirs(outputpath_results)\n",
    "\n",
    "imgs_name = os.listdir('./dataset_v2/validation')\n",
    "for k in range(len(imgs_name)):\n",
    "  path_to_new_image = os.path.join(f'./dataset_v2/validation/{imgs_name[k]}')\n",
    "  orig_img = cv2.imread(path_to_new_image)\n",
    "  print(orig_img.shape)\n",
    "  image1 = mpimg.imread(path_to_new_image)\n",
    "  results1 = model.detect([image1], verbose=1)\n",
    "  # Display results\n",
    "  ax1 = get_ax(1)\n",
    "  r1 = results1[0]\n",
    "  masked_img = display_instances(image1, r1['rois'], r1['masks'], r1['class_ids'], \\\n",
    "                                dataset_val.class_names, r1['scores'], ax=ax1, title=\"Predictions1\")\n",
    "  print(masked_img.shape)\n",
    "  stakced = np.hstack((orig_img,masked_img))\n",
    "  cv2.imwrite(os.path.join(outputpath_results,imgs_name[k]),stakced.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHVw6RJk1cqF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QK-Fzff8k3Y8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtKqntG-rz9z"
   },
   "source": [
    "<b>populating json </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu6GdWPnk3b9"
   },
   "outputs": [],
   "source": [
    "# # from imantics import Polygons, Mask\n",
    "# import cv2, glob, os\n",
    "\n",
    "# img_paths = glob.glob( os.path.join('/content/final data/original images', '*.jpg') )\n",
    "# mask_paths = glob.glob( os.path.join('/content/final data/masks', '*.png') )\n",
    "\n",
    "# split = int( len(mask_paths)*0.7 )\n",
    "# train_mask_paths, validation_mask_paths = mask_paths[:split], mask_paths[split: ]\n",
    "# # train_image_paths, validation_image_paths = img_paths[:100], img_paths[100: 125]\n",
    "\n",
    "# def get_masks(path):\n",
    "\n",
    "#     image = cv2.imread(path)\n",
    "#     crack_color, bg_color = (54,  67, 244), (255, 255, 255)\n",
    "#     # legal_colors = [patch_color, bg_color]\n",
    "#     img = np.where(image==(54,  67, 244),255,0)\n",
    "#     if len(np.unique(img)) == 1:\n",
    "#       return {}\n",
    "\n",
    "#     #finding countours and bounding boxes\n",
    "#     result = np.array(img).astype('uint8')\n",
    "#     contours = cv2.findContours(np.array(img[:,:,0]).astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "#     count = 0\n",
    "#     curr_dict = { 'fileref': '', 'size': '', 'filename': os.path.split(path)[-1].replace('.png', '.jpg'), 'base64_img_data': '',\n",
    "#                 'file_attributes': '', 'regions': {}}\n",
    "#     for cntr in contours:\n",
    "#       x_points = [ int(cnt[0][0]) for cnt in cntr]\n",
    "#       y_points = [ int(cnt[0][1]) for cnt in cntr]\n",
    "#       temp = {'shape_attributes':{ 'name': 'Polygon', 'all_points_x': x_points,\\\n",
    "#                                    'all_points_y': y_points }, \"region_attributes\":{\"label\":\"crack\"} }\n",
    "#       curr_dict['regions'][f'{count}'] = temp\n",
    "#       count += 1\n",
    "#       # print(contours)\n",
    "#       # x,y,w,h = cv2.boundingRect(cntr)\n",
    "#       # cv2.rectangle(result, (x, y), (x+w, y+h), (255, 255, 255), 32)\n",
    "#       # print(\"x,y,w,h:\",x,y,w,h)\n",
    "\n",
    "\n",
    "#     # illegal_colors = []\n",
    "#     # for k in \n",
    "\n",
    "    \n",
    "#     # unique_colors = np.unique(image.reshape(-1, image.shape[2]), axis=0)\n",
    "#     # illegal_colors = [ list(k) for k in list(np.unique(image.reshape(-1, image.shape[2]), axis=0))\\\n",
    "#                         # if not tuple(k) in legal_colors]\n",
    "\n",
    "#     # for color in illegal_colors:\n",
    "#       # image[np.all(image == tuple(color), axis=-1)] = bg_color\n",
    "#     # cords=  np.where(image==patch_color)\n",
    "#     # x_coordinates, y_coordinates =  cords[0].tolist(), cords[1].tolist()\n",
    "    \n",
    "#     # poly_points = []\n",
    "#     # labels_dict = {}\n",
    "#     # img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # curr_dict={}\n",
    "\n",
    "#     # region_dict = { 'name': 'line', 'all_points_x': x_coordinates, 'all_points_y': y_coordinates}\n",
    "#     # curr_dict = { 'fileref': '', 'size': '', 'filename': os.path.split(img_path)[-1], 'base64_img_data': '',\n",
    "#                 # 'file_attributes': '', 'regions': {}, 'region_attributes': 'Patch'}\n",
    "\n",
    "\n",
    "#     # labels_dict[os.path.split(img_path)[-1]] = curr_dict\n",
    "#     # polygons = Mask(img).polygons()\n",
    "#     # poly_points.append((polygons.points)[0])\n",
    "\n",
    "#     return curr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84FfNxjZRqsx"
   },
   "outputs": [],
   "source": [
    "# import os, json\n",
    "\n",
    "# print( len( os.listdir('/content/drive/MyDrive/Mask_RCNN/crack_data/training') ) )\n",
    "# # data = json.loads('/content/drive/MyDrive/Mask_RCNN/crack_data/training/labels.json')\n",
    "\n",
    "# json_file_path = \"/content/drive/MyDrive/Mask_RCNN/crack_data/training/labels.json\"\n",
    "\n",
    "# with open(json_file_path, 'r') as j:\n",
    "#      contents = json.loads(j.read())\n",
    "\n",
    "# len( contents.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2clOXDYk4pTm"
   },
   "outputs": [],
   "source": [
    "# # cords=  np.where(image==patch_color)\n",
    "# # x_coordinates, y_coordinates =  cords[0].tolist(), cords[1].tolist()\n",
    "# import json\n",
    "\n",
    "# base_dir = '/content/drive/MyDrive/Mask_RCNN/crack_data'\n",
    "# if not os.path.exists(base_dir):\n",
    "#   os.makedirs(base_dir)\n",
    "\n",
    "# if not os.path.exists('/content/drive/MyDrive/Mask_RCNN/crack_data/training'):\n",
    "#   os.makedirs( '/content/drive/MyDrive/Mask_RCNN/crack_data/training' )\n",
    "\n",
    "\n",
    "# labels_dict = {}\n",
    "\n",
    "# for mask_path in train_mask_paths:\n",
    "\n",
    "#   result_dict= get_masks(mask_path)\n",
    "#   if len(result_dict) == 0:\n",
    "#     continue\n",
    "\n",
    "#   labels_dict[os.path.split(mask_path)[-1]] = result_dict\n",
    "#   # break\n",
    "#   extensionles_path = os.path.split(mask_path)[-1].split('.')[0]\n",
    "#   image = cv2.imread( os.path.join('/content/final data/original images/', f'{extensionles_path}.jpg' ))\n",
    "#   # print(image.shape)\n",
    "#   cv2.imwrite(os.path.join('/content/drive/MyDrive/Mask_RCNN/crack_data/training', f'{extensionles_path}.jpg'), image )\n",
    "\n",
    "# label_path = '/content/drive/MyDrive/Mask_RCNN/crack_data/training/labels.json'\n",
    "# with open(label_path, 'w') as json_file:\n",
    "#     json.dump(labels_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE_ch56qf1xO"
   },
   "outputs": [],
   "source": [
    "# # cords=  np.where(image==patch_color)\n",
    "# # x_coordinates, y_coordinates =  cords[0].tolist(), cords[1].tolist()\n",
    "# import json\n",
    "\n",
    "# # base_dir = '/content/drive/MyDrive/Mask_RCNN/patch_data'\n",
    "# # if not os.path.exists(base_dir):\n",
    "#   # os.makedirs(base_dir)\n",
    "\n",
    "# if not os.path.exists('/content/drive/MyDrive/Mask_RCNN/crack_data/validation'):\n",
    "#   os.makedirs( '/content/drive/MyDrive/Mask_RCNN/crack_data/validation' )\n",
    "\n",
    "\n",
    "# labels_dict = {}\n",
    "\n",
    "# for mask_path in validation_mask_paths:\n",
    "\n",
    "#   result_dict= get_masks(mask_path)\n",
    "#   if len(result_dict) == 0:\n",
    "#     continue\n",
    "\n",
    "#   labels_dict[os.path.split(mask_path)[-1]] = result_dict\n",
    "\n",
    "#   extensionles_path = os.path.split(mask_path)[-1].split('.')[0]\n",
    "#   image = cv2.imread( os.path.join('/content/final data/original images/', f'{extensionles_path}.jpg' ))\n",
    "#   print(image.shape)\n",
    "#   cv2.imwrite(os.path.join('/content/drive/MyDrive/Mask_RCNN/crack_data/validation', f'{extensionles_path}.jpg'), image )\n",
    "\n",
    "# label_path = '/content/drive/MyDrive/Mask_RCNN/crack_data/validation/labels.json'\n",
    "# with open(label_path, 'w') as json_file:\n",
    "#     json.dump(labels_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qehH5n2MJM86"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hasu5NQHTM4S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_7oLD3hTM72"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # read image\n",
    "# img = cv2.imread('/content/final data/masks/201021_170008099_Camera_7.png')\n",
    "# print(img.shape)\n",
    "# #only getting cracks mask\n",
    "\n",
    "# img = np.where(img==(54,  67, 244),255,0)\n",
    "\n",
    "# #finding countours and bounding boxes\n",
    "# result = np.array(img).astype('uint8')\n",
    "# contours = cv2.findContours(np.array(img[:,:,0]).astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "# for cntr in contours:\n",
    "#     cntr1 = cntr\n",
    "#     # exit()\n",
    "#     x,y,w,h = cv2.boundingRect(cntr)\n",
    "#     cv2.rectangle(result, (x, y), (x+w, y+h), (255, 255, 255), 32)\n",
    "#     print(\"x,y,w,h:\",x,y,w,h)\n",
    "# plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMmc41kql1rG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "all class_orig_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
